{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prey notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import neat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import multimodal_mazes\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas \n",
    "\n",
    "* Odour - constant but noisy. \n",
    "* Sound - reliable but infrequent.\n",
    "* Rather than resetting the env to zero every step, you could decay it. E.g. env[:,:,:-1] *= 0.8 + blur. \n",
    "* Analysis: n_prey caught, speed, costs (e.g. movement vs food). \n",
    "* Evolve prey against different algorithms. Then, evolve predators against these prey.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "size = 7\n",
    "n_prey = 10\n",
    "n_steps = 50\n",
    "n_trials = 100\n",
    "pk = 5 # the width of the prey's Gaussian signal (in rc)\n",
    "scenario = \"Hunting\"\n",
    "\n",
    "if scenario == \"Foraging\":\n",
    "    pc = 0.0\n",
    "    pm = None\n",
    "    pe = None \n",
    "    motion = None\n",
    "elif scenario == \"Hunting\":\n",
    "    pc = 0.0\n",
    "    pm = 0.5\n",
    "    pe = 0.2\n",
    "    motion = \"Levy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=10)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies + [\"Levy\"]\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors + [list(np.array([24, 156, 196, 255]) / 255)]\n",
    "results = np.zeros((len(noises), len(policies)))\n",
    "\n",
    "# Test agents\n",
    "for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "        if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "        elif policy in multimodal_mazes.AgentRuleBasedMemory.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha = 0.6\n",
    "        elif policy == \"Levy\":\n",
    "            agnt = multimodal_mazes.AgentRandom(location=None, channels=[0,0], motion=policy)\n",
    "\n",
    "        fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, motion=motion, pc=pc, pm=pm, pe=pe)\n",
    "\n",
    "        results[a, b] = fitness\n",
    "\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(noises, results[:,b], color=colors[b], label=policy)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor Noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise AUC \n",
    "auc = np.trapz(y=results.T, x=noises, axis=1)\n",
    "for b, _ in enumerate(policies): \n",
    "    ml, sl, _ = plt.stem(b, auc[b] - auc[0])\n",
    "    ml.set_color(colors[b])\n",
    "    sl.set_color(colors[b])\n",
    "plt.xticks(range(len(policies)), policies, rotation='vertical')\n",
    "plt.ylabel('AUC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding alpha for the memory based agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=13)\n",
    "policies = multimodal_mazes.AgentRuleBasedMemory.policies\n",
    "alphas = np.linspace(start=0.0, stop=2.0, num=11)\n",
    "results = np.zeros((len(noises), len(policies), len(alphas)))\n",
    "\n",
    "# Test agents\n",
    "for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "\n",
    "        for c, alpha in enumerate(alphas):\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha=alpha\n",
    "            fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "            results[a, b, c] = fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "colors = multimodal_mazes.AgentRuleBasedMemory.colors\n",
    "auc = np.trapz(y=results.T, x=noises, axis=2)\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(alphas, auc[:,b], color=colors[b], label=policy)\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring task parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=3)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies + [\"Levy\"]\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors + [list(np.array([24, 156, 196, 255]) / 255)]\n",
    "pms = np.linspace(start=0.0, stop=1.0, num=3)\n",
    "pes = np.linspace(start=0.0, stop=1.0, num=3)\n",
    "\n",
    "results = np.zeros((len(noises), len(policies), len(pms), len(pes)))\n",
    "\n",
    "# Test agents\n",
    "for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "        if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "        elif policy in multimodal_mazes.AgentRuleBasedMemory.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha = 0.6\n",
    "        elif policy == \"Levy\":\n",
    "            agnt = multimodal_mazes.AgentRandom(location=None, channels=[0,0], motion=policy)\n",
    "\n",
    "        for c, pm in enumerate(pms):\n",
    "            for d, pe in enumerate(pes):\n",
    "                fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, motion=motion, pc=pc, pm=pm, pe=pe)\n",
    "\n",
    "                results[a, b, c, d] = fitness\n",
    "\n",
    "# np.save(\"results_\" + motion, results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results \n",
    "results = np.load(\"../results/test18/results.npy\")\n",
    "print(results.shape) # noises, policies, pms, pes \n",
    "\n",
    "parameters = np.load(\"../results/test18/parameters.npy\", allow_pickle=True)\n",
    "noises = parameters.item().get(\"noises\")\n",
    "policies = parameters.item().get(\"policies\")\n",
    "pms = parameters.item().get(\"pms\")\n",
    "pes = parameters.item().get(\"pes\")\n",
    "colors = parameters.item().get(\"colors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean AUC \n",
    "auc = np.zeros((len(policies), len(pms), len(pes)))\n",
    "for c, _ in enumerate(pms):\n",
    "    for d, _ in enumerate(pes):\n",
    "        auc[:,c,d] = np.trapz(y=results[:,:,c,d].T, x=noises, axis=1)\n",
    "\n",
    "for b, _ in enumerate(policies): \n",
    "    ml, sl, _ = plt.stem(b, np.mean(auc[b]) - np.mean(auc[0]))\n",
    "    ml.set_color(colors[b])\n",
    "    sl.set_color(colors[b])\n",
    "plt.xticks(range(len(policies)), policies, rotation='vertical')\n",
    "plt.ylabel('Normalised mean AUC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in AUC \n",
    "auc_diff = auc[-2,:,:] - auc[-5,:,:]\n",
    "print(auc_diff.min(), np.argwhere(auc_diff == np.min(auc_diff))) \n",
    "print(auc_diff.max(), np.argwhere(auc_diff == np.max(auc_diff))) \n",
    "\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(noises, results[:,\n",
    "        b, \n",
    "        np.argwhere(auc_diff == np.max(auc_diff))[0][0], \n",
    "        np.argwhere(auc_diff == np.max(auc_diff))[0][1]], \n",
    "        color=colors[b], \n",
    "        label=policy)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor Noise')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat results (# noises, policies, pms, pes)\n",
    "results_arrays = [[] for _ in enumerate(policies)]\n",
    "for a, noise in enumerate(noises):\n",
    "    for b, policy in enumerate(policies):\n",
    "        for c, pm in enumerate(pms):\n",
    "            for d, pe in enumerate(pes):\n",
    "                results_arrays[b].append([noise, pm, pe, results[a, b, c, d]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve fits \n",
    "params = [\"Sensor noise\", \"$p_m$\", \"$p_e$\"]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=len(params), figsize=(15,5), sharex=False, sharey=True)\n",
    "\n",
    "for a, policy in enumerate(policies):\n",
    "    data = np.array(results_arrays[a])   \n",
    "\n",
    "    for b, param in enumerate(params):\n",
    "        plt.sca(ax[b])\n",
    "\n",
    "        # Data \n",
    "        x = data[:,b]\n",
    "        y = data[:,-1]\n",
    "        idx = np.argsort(x)\n",
    "\n",
    "        # Poly fit \n",
    "        curve = np.poly1d(np.polyfit(x[idx],y[idx],deg=2))\n",
    "        plt.plot(x[idx], curve(x[idx]), color=colors[a], label=policy)\n",
    "        \n",
    "        if (a == 0) and (b == 0): \n",
    "            plt.ylabel(\"Fitness\")\n",
    "        \n",
    "        if (a==0):\n",
    "            plt.xlabel(param)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.concatenate((np.load(\"../results/test17/results_Brownian.npy\"), np.load(\"../results/test17/results_Levy.npy\")), axis=1)\n",
    "print(results.shape)\n",
    "\n",
    "auc = np.zeros((len(policies)*2, len(pms), len(pes)))\n",
    "for c, _ in enumerate(pms):\n",
    "    for d, _ in enumerate(pes):\n",
    "        auc[:,c,d] = np.trapz(y=results[:,:,c,d].T, x=noises, axis=1)\n",
    "\n",
    "for b, _ in enumerate(policies): \n",
    "    plt.scatter(np.mean(auc[b]), np.mean(auc[b + len(policies)]), color=colors[b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy='Linear fusion')\n",
    "noise = 0.1\n",
    "time, path, prey_state, preys = multimodal_mazes.predator_trial(size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk,n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "print(prey_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "from matplotlib import colors\n",
    "prey_markers = ['P', 'X']\n",
    "\n",
    "# Environment \n",
    "pk_hw = pk // 2  # half width of prey's Gaussian signal (in rc)\n",
    "env = np.zeros((size, size, len(agnt.channels) + 1))\n",
    "env[:, :, -1] = 1.0\n",
    "env = np.pad(env, pad_width=((pk_hw, pk_hw), (pk_hw, pk_hw), (0, 0)))\n",
    "plt.imshow(1 - env[:, :, -1], cmap=\"binary\", alpha=0.25)\n",
    "\n",
    "# Path\n",
    "cmap = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"xkcd:teal blue\", \"xkcd:off white\", \"xkcd:coral\"], N=n_steps\n",
    ")\n",
    "for t in range(len(path) - 1):\n",
    "    plt.plot([path[t, 1], path[t + 1, 1]], [path[t, 0], path[t + 1, 0]], c=cmap(t), zorder=0)\n",
    "    plt.scatter(path[t + 1, 1], path[t + 1, 0], s=30, color=cmap(t), zorder=1)\n",
    "\n",
    "# Prey \n",
    "for prey in preys:\n",
    "    path = np.array(prey.path)\n",
    "    if scenario == \"Foraging\":\n",
    "        plt.scatter(path[0,1], path[0,0], color='k', alpha=0.5, marker=prey_markers[prey.cues], zorder=2)\n",
    "    elif scenario == \"Hunting\":\n",
    "        plt.scatter(path[-1,1], path[-1,0], color='k', alpha=0.5, marker=prey_markers[0], zorder=2)\n",
    "\n",
    "# Adjust axes \n",
    "plt.xlim([(pk//2) - 1, size + pk//2])\n",
    "plt.ylim([size + pk//2, (pk//2) - 1]) \n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP: Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy='Linear fusion')\n",
    "noise = 0.1\n",
    "time, path, prey_state, preys, env_log = multimodal_mazes.predator_trial(size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk,n_steps=n_steps, scenario=scenario, motion=\"Levy\", pc=pc, pm=pm, pe=pe, log_env=True)\n",
    "print(prey_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "prey_markers = ['P', 'X']\n",
    "\n",
    "# Colormaps \n",
    "from matplotlib import colors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "cmap_wall = cm.binary\n",
    "cmap_wall.set_under('k', alpha=0)\n",
    "\n",
    "cmap_ch0 = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:ultramarine\"]\n",
    ")\n",
    "\n",
    "cmap_ch1 = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:magenta\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Environment \n",
    "plt.imshow(1 - env_log[0][:, :, -1], clim=[0.1,1.0], cmap=cmap_wall, alpha=0.25, zorder=1)\n",
    "\n",
    "# Adjust axes \n",
    "plt.xlim([(pk//2) - 1, size + pk//2])\n",
    "plt.ylim([size + pk//2, (pk//2) - 1]) \n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Initial data \n",
    "agnt_animation = ax.scatter([], [], s=120, color='k', zorder=3)\n",
    "preys_animation = [[] for _ in preys]\n",
    "for a, prey in enumerate(preys): \n",
    "    if scenario == \"Foraging\":\n",
    "        preys_animation[a] = ax.scatter([], [], s=60, color='k', alpha=0.5, marker=prey_markers[prey.cues], zorder=2)\n",
    "    elif scenario == \"Hunting\": \n",
    "        preys_animation[a] = ax.scatter([], [], s=60, color='k', alpha=0.5, marker=prey_markers[0], zorder=2)\n",
    "\n",
    "# Animate \n",
    "def update_animation(t):\n",
    "    plt.imshow((cmap_ch0(env_log[t][:,:,0]) + cmap_ch1(env_log[t][:,:,1]))/2, interpolation='gaussian', zorder=0) \n",
    "\n",
    "    agnt_animation.set_offsets([path[t, 1], path[t, 0]])\n",
    "\n",
    "    for a, prey in enumerate(preys): \n",
    "        try:\n",
    "            preys_animation[a].set_offsets([prey.path[t][1], prey.path[t][0]])\n",
    "        except:\n",
    "            preys_animation[a].set(alpha=0)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_animation, frames=range(1, len(path)), blit=False)\n",
    "anim.save(\"Test.gif\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 channel colormap\n",
    "input_values = np.linspace(0,1,num=11)\n",
    "a,b = np.meshgrid(input_values, input_values)\n",
    "\n",
    "plt.imshow((cmap_ch0(a) + cmap_ch1(b))/2, zorder=0, origin='lower')\n",
    "plt.xticks(ticks=range(len(input_values)), labels=np.round(input_values,1), rotation='vertical')\n",
    "plt.yticks(ticks=range(len(input_values)), labels=np.round(input_values,1))\n",
    "plt.xlabel('Ch0 input')\n",
    "plt.ylabel('Ch1 input')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
