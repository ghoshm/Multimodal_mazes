{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prey notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import neat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import multimodal_mazes\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas \n",
    "\n",
    "* Odour - constant but noisy. \n",
    "* Sound - reliable but infrequent.\n",
    "* Rather than resetting the env to zero every step, you could decay it. E.g. env[:,:,:-1] *= 0.8 + blur. \n",
    "* Analysis: n_prey caught, speed, costs (e.g. movement vs food). \n",
    "* Evolve prey against different algorithms. Then, evolve predators against these prey.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "size = 7\n",
    "n_prey = 10\n",
    "n_steps = 50\n",
    "n_trials = 100\n",
    "pk = 5 # the width of the prey's Gaussian signal (in rc)\n",
    "scenario = \"Hunting\"\n",
    "pm = 0.1\n",
    "pe = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=13)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors\n",
    "results = np.zeros((len(noises), len(policies)))\n",
    "\n",
    "# Test agents\n",
    "for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "        if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "        else:\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha = 0.6\n",
    "\n",
    "        fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "\n",
    "        results[a, b] = fitness\n",
    "\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(noises, results[:,b], color=colors[b], label=policy)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor Noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise AUC \n",
    "auc = np.trapz(y=results.T, x=noises, axis=1)\n",
    "for b, _ in enumerate(policies): \n",
    "    ml, sl, _ = plt.stem(b, auc[b])\n",
    "    ml.set_color(colors[b])\n",
    "    sl.set_color(colors[b])\n",
    "plt.xticks(range(len(policies)), policies, rotation='vertical')\n",
    "plt.ylabel('AUC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding alpha for the memory based agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=13)\n",
    "policies = multimodal_mazes.AgentRuleBasedMemory.policies\n",
    "alphas = np.linspace(start=0.0, stop=2.0, num=11)\n",
    "results = np.zeros((len(noises), len(policies), len(alphas)))\n",
    "\n",
    "# Test agents\n",
    "for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "\n",
    "        for c, alpha in enumerate(alphas):\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha=alpha\n",
    "            fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "            results[a, b, c] = fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "colors = multimodal_mazes.AgentRuleBasedMemory.colors\n",
    "auc = np.trapz(y=results.T, x=noises, axis=2)\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(alphas, auc[:,b], color=colors[b], label=policy)\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring task parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=2.0, num=10)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors\n",
    "pms = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "pes = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "\n",
    "# results = np.zeros((len(noises), len(policies), len(pms), len(pes)))\n",
    "\n",
    "# # Test agents\n",
    "# for a, noise in enumerate(tqdm(noises)):\n",
    "\n",
    "#     for b, policy in enumerate(policies): \n",
    "#         if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "#             agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "#         else:\n",
    "#             agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "#             agnt.alpha = 0.6\n",
    "\n",
    "#         for c, pm in enumerate(pms):\n",
    "#             for d, pe in enumerate(pes):\n",
    "#                 fitness, _, _, _ = multimodal_mazes.eval_predator_fitness(n_trials=n_trials, size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "\n",
    "#                 results[a, b, c, d] = fitness\n",
    "\n",
    "# np.save('results_noise', results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results \n",
    "results = np.load(\"../results/test17/results_noise.npy\")\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean AUC \n",
    "auc = np.zeros((len(policies), len(pms), len(pes)))\n",
    "for c, _ in enumerate(pms):\n",
    "    for d, _ in enumerate(pes):\n",
    "        auc[:,c,d] = np.trapz(y=results[:,:,c,d].T, x=noises, axis=1)\n",
    "\n",
    "for b, _ in enumerate(policies): \n",
    "    ml, sl, _ = plt.stem(b, np.mean(auc[b]) - np.mean(auc[0]))\n",
    "    ml.set_color(colors[b])\n",
    "    sl.set_color(colors[b])\n",
    "plt.xticks(range(len(policies)), policies, rotation='vertical')\n",
    "plt.ylabel('Normalised mean AUC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_diff = results[:,-1,:,:] - results[:,-4,:,:]\n",
    "print(np.argwhere(results_diff == np.max(results_diff))) # noises, pms, pes \n",
    "print(results_diff.min(), results_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for a, noise in enumerate(noises):\n",
    "    for b, pm in enumerate(pms):\n",
    "        for c, pe in enumerate(pes):\n",
    "            results_list.append([noise, pm, pe, results_diff[a,b,c]])\n",
    "results_list = np.array(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "a = 0\n",
    "plt.scatter(results_list[:,a], results_list[:,-1], c='k', marker='.', alpha=0.2)\n",
    "model = LinearRegression().fit(results_list[:, a][:, None], results_list[:,-1])\n",
    "plt.plot(\n",
    "        results_list[:, a],\n",
    "        model.predict(results_list[:, a][:, None]),\n",
    "        color=\"xkcd:coral pink\",\n",
    "        alpha=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy='Linear fusion')\n",
    "noise = 0.1\n",
    "# agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy='Recurrent outputs')\n",
    "# agnt.alpha=0.9\n",
    "time, path, prey_state, preys = multimodal_mazes.predator_trial(size=size, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk,n_steps=n_steps, scenario=scenario, pm=pm, pe=pe)\n",
    "print(prey_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "from matplotlib import colors\n",
    "prey_markers = ['P', 'X']\n",
    "\n",
    "# Environment \n",
    "pk_hw = pk // 2  # half width of prey's Gaussian signal (in rc)\n",
    "env = np.zeros((size, size, len(agnt.channels) + 1))\n",
    "env[:, :, -1] = 1.0\n",
    "env = np.pad(env, pad_width=((pk_hw, pk_hw), (pk_hw, pk_hw), (0, 0)))\n",
    "plt.imshow(1 - env[:, :, -1], cmap=\"binary\", alpha=0.25)\n",
    "\n",
    "# Path\n",
    "cmap = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"xkcd:teal blue\", \"xkcd:off white\", \"xkcd:coral\"], N=n_steps\n",
    ")\n",
    "for t in range(len(path) - 1):\n",
    "    plt.plot([path[t, 1], path[t + 1, 1]], [path[t, 0], path[t + 1, 0]], c=cmap(t), zorder=0)\n",
    "    plt.scatter(path[t + 1, 1], path[t + 1, 0], s=30, color=cmap(t), zorder=1)\n",
    "\n",
    "# Prey \n",
    "for prey in preys:\n",
    "    path = np.array(prey.path)\n",
    "    if scenario == \"Foraging\":\n",
    "        plt.scatter(path[0,1], path[0,0], color='k', alpha=0.5, marker=prey_markers[prey.cues], zorder=2)\n",
    "\n",
    "    if scenario == \"Hunting\":\n",
    "        plt.scatter(path[-1,1], path[-1,0], color='k', alpha=0.5, marker=prey_markers[0], zorder=2)\n",
    "\n",
    "# Adjust axes \n",
    "plt.xlim([(pk//2) - 1, size + pk//2])\n",
    "plt.ylim([size + pk//2, (pk//2) - 1]) \n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIP: Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:ultramarine\"]\n",
    ")\n",
    "\n",
    "cmap1 = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:magenta\"]\n",
    ")\n",
    "\n",
    "plt.imshow((cmap(env[:,:,0]) + cmap1(env[:,:,1]))/2)\n",
    "plt.imshow(1 - env[:, :, -1], cmap=\"binary\", alpha=0.25)\n",
    "# Adjust axes \n",
    "plt.xlim([(pk//2) - 1, size + pk//2])\n",
    "plt.ylim([size + pk//2, (pk//2) - 1]) \n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
