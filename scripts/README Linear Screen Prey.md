{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "This script simulates predator-prey interactions in a multimodal maze environment. The predator's task is to capture prey, with various configurations of prey motion, multisensory inputs, and agent policies. The agent's behavior is modeled using rule-based, memory-based, or random policies. The script also includes visualizations of the predator-prey interactions and performance metrics, such as percentage capture and approach.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "1. **Imports**:\n",
    "   - Standard libraries like `numpy`, `pickle`, and `matplotlib` are used for numerical operations, data handling, and visualizations.\n",
    "   - `multimodal_mazes` is the core module providing the agent behaviors, environment settings, and prey simulation functions.\n",
    "   - `tqdm` is used for progress tracking in loops.\n",
    "\n",
    "2. **Hyperparameters**:\n",
    "   - **width/height**: Dimensions of the maze environment.\n",
    "   - **n_prey**: Number of prey in the environment.\n",
    "   - **n_steps**: Number of steps in each simulation trial.\n",
    "   - **n_trials**: Number of trials to evaluate the agent's performance.\n",
    "   - **pk**: Width of the prey’s Gaussian signal.\n",
    "   - **scenario, motion, multisensory**: Define the type of simulation scenario (e.g., Constant, Random, Two Prey), prey motion type, and whether the agent receives multisensory or unisensory inputs.\n",
    "\n",
    "3. **Agent and Prey Initialization**:\n",
    "   - Agents can have different policies (rule-based, memory-based, or random) with varying strategies for capturing prey.\n",
    "   - Prey behavior can be static or dynamic, with different noise levels and motion types.\n",
    "\n",
    "4. **Simulation Execution**:\n",
    "   - The core simulation is performed by `PredatorTrial` or similar classes in the `multimodal_mazes` package. The trial runs and logs the agent's path, prey state, and environment states.\n",
    "\n",
    "5. **Visualization**:\n",
    "   - The script includes extensive plotting functionalities:\n",
    "     - Animations of the agent’s pursuit of prey.\n",
    "     - Visualization of sensory inputs using colormaps.\n",
    "     - Plots showing performance metrics such as capture percentage vs. speed and approach percentage vs. prey visibility.\n",
    "\n",
    "6. **Performance Metrics**:\n",
    "   - **Percentage Capture vs. Speed**: Tests how well different policies capture prey at varying speeds.\n",
    "   - **Percentage Approached vs. Time**: Shows how prey visibility affects the agent’s approach percentage.\n",
    "   - **Two Prey Capture Probability**: Evaluates the probability of capturing multisensory prey first under different noise conditions.\n",
    "\n",
    "---\n",
    "\n",
    "#### Functions and Visualization Techniques\n",
    "\n",
    "- **update_animation(t)**: Updates the environment and agent-prey positions for each frame in the animation.\n",
    "  \n",
    "- **Evaluator Class**: Provides fitness evaluation for the agent's behavior, calculating metrics like capture and approach percentage for multiple trials.\n",
    "\n",
    "- **Colormap Integration**: Uses custom colormaps to represent different sensory channels and environmental factors, providing a clear visual representation of agent behavior.\n",
    "\n",
    "- **Performance Visualization**:\n",
    "   - **Line plots** for percentage capture vs. speed, approach percentage vs. time, and multisensory prey capture probability.\n",
    "   - **Error bars** represent the variability across multiple simulation runs (standard deviation).\n",
    "  \n",
    "---\n",
    "\n",
    "#### Key Parameters for Customization\n",
    "\n",
    "- **Scenario and Motion Types**:\n",
    "   - Scenario options include static, constant, random, and two-prey situations.\n",
    "   - Motion can be linear, Levy, or custom types for prey movements.\n",
    "  \n",
    "- **Agent Policies**:\n",
    "   - Policies include several predefined rule-based, memory-based, and random strategies, such as \"Nonlinear fusion,\" \"Levy motion,\" or \"Kinetic alignment.\"\n",
    "\n",
    "- **Multisensory or Unisensory Inputs**:\n",
    "   - The agent can be tested in different sensory environments (e.g., unisensory, balanced multisensory) to explore how different sensory strategies affect predator-prey dynamics.\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "This script simulates predator-prey interactions in various complex environments and provides both qualitative (visualization) and quantitative (metrics) insights into agent performance. It is highly customizable, with options for adjusting scenario settings, agent policies, and sensory conditions to explore a wide range of behavioral dynamics in the simulated environment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
