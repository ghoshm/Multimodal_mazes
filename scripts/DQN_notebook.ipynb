{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import neat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import pickle\n",
    "import multimodal_mazes\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas \n",
    "* Optuna: https://colab.research.google.com/github/araffin/tools-for-robotic-rl-icra2022/blob/main/notebooks/optuna_lab.ipynb#scrollTo=E0yEokTDxhrC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt = multimodal_mazes.AgentDQN(location=[5,5], channels=[1,1], sensor_noise_scale=0.05, n_hidden_units=8, wm_flags=np.array([0,0,0,0,0,0,1]))\n",
    "agnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze.generate(number=1000, noise_scale=0.0, gaps=0)\n",
    "agnt.generate_policy(maze, n_steps=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(agnt.output_to_hidden.weight.grad)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise\n",
    "noises = np.linspace(start=0.0, stop=0.5, num=21)\n",
    "\n",
    "# Small set\n",
    "wm_flags = np.array([[0,0,0,0,0,0,0], [0,0,0,0,0,0,0], [1,1,1,1,0,0,0],[1,1,1,1,1,1,1]])\n",
    "colors = [\"xkcd:gray\", [0.0, 0.0, 0.0, 0.5], [0.039, 0.73, 0.71, 1], list(np.array([24, 156, 196, 255]) / 255)]\n",
    "\n",
    "# Full set \n",
    "# wm_flags = np.array(list(itertools.product([0,1], repeat=7)))\n",
    "# wm_flags = np.vstack((wm_flags[0], wm_flags))\n",
    "# colors = cm.get_cmap(\"plasma\", len(wm_flags)).colors.tolist()\n",
    "\n",
    "results = np.zeros((len(noises), len(wm_flags)))\n",
    "\n",
    "# Generate mazes\n",
    "maze = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze.generate(number=100000, noise_scale=0.0, gaps=2)\n",
    "\n",
    "maze_test = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze_test.generate(number=1000, noise_scale=0.0, gaps=2)\n",
    "\n",
    "# Run\n",
    "for b, wm_flag in enumerate(tqdm(wm_flags)): \n",
    "\n",
    "    # Control architecture \n",
    "    if b != 1: \n",
    "        n_hidden_units = 8\n",
    "    else:\n",
    "        n_hidden_units = 34 \n",
    "    \n",
    "    # Train\n",
    "    agnt = multimodal_mazes.AgentDQN(location=[5,5], channels=[1,1], sensor_noise_scale=0.05, n_hidden_units=n_hidden_units, wm_flags=wm_flag)\n",
    "    agnt.generate_policy(maze, n_steps=6) \n",
    "\n",
    "    # Test \n",
    "    for a, noise in enumerate(noises):\n",
    "        results[a,b] = multimodal_mazes.eval_fitness(genome=None, config=None, channels=[1,1], sensor_noise_scale=noise, drop_connect_p=0.0, maze=maze_test, n_steps=6, agnt=agnt)\n",
    "\n",
    "# Plotting\n",
    "plt.plot([0.05, 0.05], [0,1], ':', color='k', alpha=0.5, label='Training noise')\n",
    "for b, wm_flag in enumerate(wm_flags): \n",
    "    plt.plot(noises, results[:,b], color=colors[b], label=wm_flag)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise AUC \n",
    "auc = np.trapz(y=results.T, x=noises, axis=1)\n",
    "idxs = np.argsort(auc)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5*3,5), sharex=False, sharey=True)\n",
    "for b, idx in enumerate(idxs): \n",
    "    ml, sl, _ = plt.stem(b, auc[idx])\n",
    "    ml.set_color('k')\n",
    "    sl.set_color('k')\n",
    "# plt.xticks(range(len(wm_flags)), policies, rotation='vertical')\n",
    "plt.ylabel('AUC');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "paths = ['../Results/test' + str(n) + '/' for n in range(58,68)]\n",
    "print(paths)\n",
    "\n",
    "noises = np.linspace(start=0.0, stop=0.5, num=21) # noises,\n",
    "results = np.zeros((len(noises), 129, len(paths))) * np.nan # noises x architectures x repeats\n",
    "wm_flags = np.zeros((129, 7, len(paths))) * np.nan # architectures x flags x repeats\n",
    "n_parameters = np.zeros((129, len(paths))) * np.nan # architectures x repeats\n",
    "auc = np.zeros((129, len(paths))) * np.nan # architectures x repeats \n",
    "\n",
    "for a, path in enumerate(tqdm(paths)):\n",
    "\n",
    "    # Load data \n",
    "    for f in os.listdir(path):\n",
    "        if f.endswith(\".pickle\"):\n",
    "            with open(path + f, 'rb') as file:\n",
    "                agnt = pickle.load(file)\n",
    "                idx = int(os.path.splitext(f)[0])\n",
    "\n",
    "                results[:, idx, a] = agnt.results\n",
    "                wm_flags[idx, :, a] = agnt.wm_flags\n",
    "                n_parameters[idx, a] = agnt.n_parameters\n",
    "                auc[idx, a] = np.trapz(y=agnt.results, x=noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph features \n",
    "import networkx as nx\n",
    "from scipy.linalg import expm\n",
    "\n",
    "Gs, communcability, n_cycles, cycle_c = [], [], [], []\n",
    "for a, wm_flag in enumerate(np.nanmax(wm_flags, axis=2)):\n",
    "    G = nx.DiGraph([(0,1), (1,2)]) # F0 and F1 \n",
    "    if wm_flag[0]: G.add_edge(0,0) # L0\n",
    "    if wm_flag[1]: G.add_edge(1,1) # L1\n",
    "    if wm_flag[2]: G.add_edge(2,2) # L2\n",
    "    if wm_flag[3]: G.add_edge(0,2) # S0\n",
    "    if wm_flag[4]: G.add_edge(2,0) # S1\n",
    "    if wm_flag[5]: G.add_edge(1,0) # B0\n",
    "    if wm_flag[6]: G.add_edge(2,1) # B1\n",
    "\n",
    "    Gs.append(G)\n",
    "    communcability.append(np.mean(expm(nx.adjacency_matrix(G).toarray())))\n",
    "    n_cycles.append(len(list(nx.simple_cycles(G))))\n",
    "    try:\n",
    "        cycle_c.append(max([len(c) for c in nx.simple_cycles(G)]))\n",
    "    except: \n",
    "        cycle_c.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting\n",
    "idxs = np.argsort(np.nanmax(auc,axis=1) - np.nanstd(auc,axis=1)) # Sort by max minus std  \n",
    "\n",
    "# Networks of interest\n",
    "# interest = [1,128, np.argmax(np.nanmean(results[2,:,:], axis=1)), np.argmax(np.nanmean(auc, axis=1))]\n",
    "# i_cols = ['xkcd:dusty blue', 'xkcd:purple', 'xkcd:dark seafoam', 'xkcd:yellowish']\n",
    "# i_labels = ['Feedforward (L)', 'Fully recurrent', 'Most accurate', 'Most robust']\n",
    "\n",
    "interest = [74, 10, 66, 73]\n",
    "i_cols = ['xkcd:dark seafoam', 'xkcd:wintergreen', 'xkcd:tree green', 'xkcd:pale lime']\n",
    "i_labels = ['None', 'L0', 'S0', 'B1']\n",
    "\n",
    "# interest = [74]\n",
    "\n",
    "# np.argwhere((np.nanmax(wm_flags, axis=2) == [1,0,0,1,0,0,0]).all(1))\n",
    "# interest = [74, 10,66, 73]\n",
    "# interest = [65, 33, 17]\n",
    "\n",
    "print(interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC vs paramters (scatters and curve fits)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10*2,5), sharex=True, sharey=False)\n",
    "\n",
    "for a in range(2):\n",
    "    plt.sca(ax[a])\n",
    "    \n",
    "    x = n_parameters.reshape(-1) # networks,\n",
    "\n",
    "    if a == 0: \n",
    "        y = results[2,:,:].reshape(-1) # networks,\n",
    "        plt.ylabel('Test accuracy')\n",
    "\n",
    "    if a == 1: \n",
    "        y = auc.reshape(-1) # networks,\n",
    "        plt.ylabel('Robustness to noise')\n",
    "\n",
    "    # if a == 2: \n",
    "    #     x = np.repeat(communcability, repeats=len(paths)) # networks\n",
    "    #     plt.xlabel('Mean communcability')\n",
    "\n",
    "    z = np.repeat(np.arange(start=0, stop=129), repeats=len(paths)) # networks\n",
    "\n",
    "    x = x[np.isnan(y) == False]\n",
    "    z = z[np.isnan(y) == False]\n",
    "    y = y[np.isnan(y) == False]\n",
    "\n",
    "    idx = np.argsort(x)\n",
    "\n",
    "    curve = np.poly1d(np.polyfit(x[idx],y[idx],deg=2))\n",
    "    plt.plot(x[idx], curve(x[idx]), color='xkcd:grey', alpha=0.5)\n",
    "\n",
    "    plt.scatter(x, y, s=10, color='k', marker='.', alpha=0.2, label='All networks')\n",
    "\n",
    "    for b, i in enumerate(interest):\n",
    "        plt.scatter(x[z == i], y[z == i], color=i_cols[b], marker='.', alpha=0.75, label=i_labels[b])\n",
    "    \n",
    "    if a == 0:\n",
    "        plt.legend(loc='upper left')\n",
    "    \n",
    "    plt.xlabel('Number of parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise AUC \n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "wm_f_labels = ['L0', 'L1', 'L2', 'S0', 'S1', 'B0', 'B1']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(5*3,5), sharex=True, sharey=False)\n",
    "\n",
    "plt.sca(ax[0])\n",
    "plt.plot([range(129), range(129)], [np.nanmin(auc,axis=1)[idxs], np.nanmax(auc,axis=1)[idxs]], color='k', alpha=0.25);\n",
    "plt.ylabel('AUC');\n",
    "plt.xticks([])\n",
    "\n",
    "plt.sca(ax[1])\n",
    "for i in range(7):\n",
    "    plt.scatter(range(129), np.ones(129) * i, c=[(0, 0, 0, alpha) for alpha in np.nanmax(wm_flags, axis=2)[idxs,i]], s=5)\n",
    "plt.yticks(range(7), wm_f_labels)\n",
    "plt.xlabel('Architectures')\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    plt.sca(ax[0])\n",
    "    plt.plot([np.where(idxs == i)[0], np.where(idxs == i)[0]], [np.nanmin(auc[i]), np.nanmax(auc[i])], color=i_cols[a])  \n",
    "\n",
    "    ax[1].add_patch(Rectangle((np.where(idxs == i)[0][0] -0.25, -0.95), 0.5, 7.05, color=i_cols[a], alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise \n",
    "plt.plot([0.05, 0.05], [0,1], ':', color='k', alpha=0.5, label='Training noise')\n",
    "\n",
    "plt.plot([], [], 'k', alpha=0.1, label='All architectures')\n",
    "plt.plot(noises, results[:,range(129), np.nanargmax(auc,axis=1)], c='k', alpha=0.1);\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    plt.plot(noises, results[:, i, np.nanargmax(auc[i])], color=i_cols[a], label=i_labels[a])\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor noise')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness vs noise \n",
    "plt.plot([0.05, 0.05], [0,1], ':', color='k', alpha=0.5, label='Training noise')\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    plt.plot(noises, results[:, i], color=i_cols[a], label=i_labels[a], alpha=0.5)\n",
    "\n",
    "plt.ylim([0, 1.05])\n",
    "plt.ylabel('Fitness')\n",
    "plt.xlabel('Sensor noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph features \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "Gs = []\n",
    "for a, wm_flag in enumerate(np.nanmax(wm_flags, axis=2)):\n",
    "    G = nx.DiGraph([(0,1), (1,2)]) # F0 and F1 \n",
    "    if wm_flag[0]: G.add_edge(0,0) # L0\n",
    "    if wm_flag[1]: G.add_edge(1,1) # L1\n",
    "    if wm_flag[2]: G.add_edge(2,2) # L2\n",
    "    if wm_flag[3]: G.add_edge(0,2) # S0\n",
    "    if wm_flag[4]: G.add_edge(2,0) # S1\n",
    "    if wm_flag[5]: G.add_edge(1,0) # B0\n",
    "    if wm_flag[6]: G.add_edge(2,1) # B1\n",
    "\n",
    "    Gs.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows=8, ncols=16, figsize=(30,15), sharex=True, sharey=True)\n",
    "\n",
    "for a, _ in enumerate(ax.ravel()):\n",
    "    plt.sca(ax.ravel()[a])\n",
    "\n",
    "    wm_flag = np.nanmax(wm_flags,axis=2)[a+1]\n",
    "    multimodal_mazes.plot_dqn_architecture(wm_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "multimodal_mazes.plot_dqn_architecture(np.nanmax(wm_flags,axis=2)[73])\n",
    "new_color = 'k'\n",
    "\n",
    "for line in ax.get_lines(): \n",
    "    line.set_color(new_color)\n",
    "\n",
    "for patch in ax.patches: \n",
    "    patch.set_facecolor(new_color)\n",
    "    patch.set_edgecolor(new_color)\n",
    "\n",
    "for path_collection in ax.collections:\n",
    "    path_collection.set_facecolor(new_color)\n",
    "    path_collection.set_edgecolor(new_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = np.nanmean(results[2,:,:],1) # test accuracy \n",
    "scores = np.nanmean(auc, axis=1) # robustness to noise\n",
    "wm_flags = np.nanmax(wm_flags, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def calculate_shapley_values(scores, wm_flags):\n",
    "    n_hyperparams = wm_flags.shape[1]\n",
    "    shapley_values = np.zeros(n_hyperparams)\n",
    "\n",
    "    # Iterate over each hyperparameter\n",
    "    for i in range(n_hyperparams):\n",
    "        marginal_contributions = []\n",
    "        \n",
    "        # Iterate over all possible coalitions\n",
    "        for coalition_size in range(n_hyperparams):\n",
    "            for coalition in combinations(range(n_hyperparams), coalition_size):\n",
    "                if i not in coalition:\n",
    "                    # Convert coalition to list and add the current hyperparameter\n",
    "                    coalition_with_i = list(coalition) + [i]\n",
    "                    \n",
    "                    # Calculate the indices for the coalitions with and without the hyperparameter\n",
    "                    idx_coalition = np.where(np.all(wm_flags[:, coalition] == 1, axis=1) & (wm_flags[:,i] == 0))[0]\n",
    "                    idx_coalition_with_i = np.where(np.all(wm_flags[:, coalition_with_i] == 1, axis=1))[0]\n",
    "                    assert len(np.intersect1d(idx_coalition, idx_coalition_with_i)) == 0, \"Indexing error\"\n",
    "                    \n",
    "                    # Calculate the marginal contribution and add it to the list\n",
    "                    marginal_contributions.extend(scores[idx_coalition_with_i] - scores[idx_coalition])\n",
    "        \n",
    "        # Calculate the Shapley value for the current hyperparameter as the average of its marginal contributions\n",
    "        shapley_values[i] = np.mean(marginal_contributions)\n",
    "        \n",
    "        return shapley_values\n",
    "\n",
    "# Calculate \n",
    "shapley_values = calculate_shapley_values(scores, wm_flags)\n",
    "plt.scatter(range(len(shapley_values)), shapley_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "X = np.transpose(wm_flags, (0, 2, 1)).reshape(-1,7)\n",
    "# y = results[2,:,:].reshape(-1) # test accuracy \n",
    "# y = auc.reshape(-1) # robustness to noise \n",
    "\n",
    "X = X[np.isnan(y) == False]\n",
    "y = y[np.isnan(y) == False]\n",
    "\n",
    "assert len(X) == len(y), \"Mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit random forest model\n",
    "RF_model = RandomForestRegressor()\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "scores = cross_val_score(RF_model, X, y, cv=kf, scoring=\"neg_mean_squared_error\") * -1\n",
    "print(str(np.round(np.mean(scores),3)) + \" +/- \" + str(np.round(np.std(scores),3)))\n",
    "RF_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap analysis\n",
    "explainer = shap.TreeExplainer(model=RF_model, data=X)\n",
    "shap_values = explainer.shap_values(X, check_additivity=True)\n",
    "\n",
    "feature_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "feature_ranking = np.argsort(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap plot \n",
    "labels = (\"L0\", \"L1\", \"L2\", \"S0\", \"S1\", \"B0\", \"B1\")\n",
    "colors = ((0.5, 0.5, 0.5), (1, 1, 1))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(10*2,5), sharex=False, sharey=True)\n",
    "for a, i in enumerate(feature_ranking):\n",
    "    plt.sca(ax[a])\n",
    "    plt.hlines(y=0.0, xmin=-0.5, xmax=0.5, color='xkcd:grey', zorder=0)\n",
    "    sns.violinplot(\n",
    "        x=np.zeros(shap_values.shape[0]),\n",
    "        y=shap_values[:,i], \n",
    "        hue=X[:,i], \n",
    "        palette=colors, split=True, inner=None, cut=True)\n",
    "    \n",
    "    ax[a].set_xticks([])\n",
    "    plt.xlabel(labels[i])\n",
    "\n",
    "    if a == 0: \n",
    "        plt.ylabel('Shap value')\n",
    "        # plt.ylim([-0.1, 0.1])\n",
    "        # plt.ylim([-0.025, 0.025])\n",
    "    else:\n",
    "        ax[a].get_legend().remove()\n",
    "        ax[a].spines['left'].set_visible(False)\n",
    "        ax[a].spines['bottom'].set_visible(False)\n",
    "        ax[a].tick_params(left=False, bottom=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "\n",
    "shap_values = []\n",
    "for a in tqdm(range(results.shape[0])): # for each level of noise\n",
    "    \n",
    "    # Data\n",
    "    X = np.transpose(wm_flags, (0, 2, 1)).reshape(-1,7)\n",
    "    y = results[a,:,:].reshape(-1) # accuracy \n",
    "\n",
    "    X = X[np.isnan(y) == False]\n",
    "    y = y[np.isnan(y) == False]\n",
    "\n",
    "    assert len(X) == len(y), \"Mismatch\"\n",
    "\n",
    "    # Fit random forest model\n",
    "    RF_model = RandomForestRegressor()\n",
    "    RF_model.fit(X,y)\n",
    "\n",
    "    # Shap analysis\n",
    "    explainer = shap.TreeExplainer(model=RF_model, data=X)\n",
    "    s_v = explainer.shap_values(X, check_additivity=True)\n",
    "\n",
    "    shap_values.append(np.copy(s_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_summary = np.zeros((len(shap_values), shap_values[0].shape[1])) * np.nan # noises x features\n",
    "for a in range(shap_summary.shape[0]):\n",
    "    for b in range(shap_summary.shape[1]):\n",
    "        shap_summary[a,b] = np.nanmean(shap_values[a][X[:,b] == 1, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot\n",
    "labels = (\"L0\", \"L1\", \"L2\", \"S0\", \"S1\", \"B0\", \"B1\")\n",
    "cols = [\"xkcd:teal blue\", \"xkcd:teal blue\", \"xkcd:teal blue\", \"xkcd:topaz\", \"xkcd:topaz\", \"xkcd:orange\",\"xkcd:orange\"]\n",
    "alphas = [1.0, 0.75, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
    "\n",
    "ylim = [np.min(shap_summary) * 1.1, np.max(shap_summary) * 1.1]\n",
    "plt.vlines(x=0.05, ymin=ylim[0], ymax=ylim[1], linestyles=\":\", color='k', alpha=0.5, label='Training noise')\n",
    "for a in range(shap_summary.shape[1]):\n",
    "    plt.plot(noises, shap_summary[:,a], color=cols[a], alpha=alphas[a], label=labels[a])\n",
    "\n",
    "plt.xlabel('Sensor noise')\n",
    "plt.ylabel('Shap value')\n",
    "plt.ylim(ylim)\n",
    "\n",
    "plt.legend(loc=\"upper center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy \n",
    "paths = ['../Results/test' + str(n) + '/' for n in range(58,68)]\n",
    "print(paths)\n",
    "\n",
    "interest = [1, 128, 74, 36]\n",
    "i_cols = ['xkcd:dusty blue', 'xkcd:purple', 'xkcd:dark seafoam', 'xkcd:yellowish']\n",
    "i_labels = ['Feedforward (L)', 'Fully recurrent', 'Most accurate', 'Most robust']\n",
    "\n",
    "# interest = [74, 10, 66, 73]\n",
    "# i_cols = ['xkcd:dark seafoam', 'xkcd:wintergreen', 'xkcd:tree green', 'xkcd:pale lime']\n",
    "# i_labels = ['None', 'L0', 'S0', 'B1']\n",
    "\n",
    "# interest = [73]\n",
    "\n",
    "# interest = list(np.arange(0,129))\n",
    "\n",
    "agents, idxs = [], []\n",
    "for a, path in enumerate(tqdm(paths)):\n",
    "\n",
    "    # Load data \n",
    "    for f in interest:\n",
    "        try:\n",
    "            with open(path + str(f) + \".pickle\", 'rb') as file:\n",
    "                    agnt = pickle.load(file)\n",
    "                    agents.append(agnt)\n",
    "                    idxs.append(f)\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "print(np.unique(idxs, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity (Jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "from scipy.optimize import curve_fit\n",
    "import copy \n",
    "\n",
    "def gaussian(x, amp, mean, stddev):\n",
    "    return amp * np.exp(-((x - mean) ** 2) / (2 * stddev ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating sensitivity\n",
    "import seaborn as sns\n",
    "\n",
    "sensor_noise_scale = 0.05 \n",
    "n_steps = 6 \n",
    "\n",
    "maze = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze.generate(number=1000, noise_scale=0, gaps=2)\n",
    "\n",
    "popts = []\n",
    "for a, i in enumerate(tqdm(interest)): # for each architecture\n",
    "    for _, v in enumerate(np.where(np.array(idxs) == i)[0]): # for each network\n",
    "        agnt = copy.deepcopy(agents[v])\n",
    "        all_states = []        \n",
    "\n",
    "        # Collect states\n",
    "        _, all_states = multimodal_mazes.eval_fitness(\n",
    "            genome=None, config=None, channels=agnt.channels, \n",
    "            sensor_noise_scale=sensor_noise_scale, drop_connect_p=0.0, \n",
    "            maze=maze, n_steps=n_steps, agnt=agnt, record_states=True)\n",
    "\n",
    "        # Calculate jacobian norms    \n",
    "        xs, ys = multimodal_mazes.calculate_dqn_input_sensitivity(all_states, agnt)\n",
    "        idx = np.argsort(xs)\n",
    "\n",
    "        # Fit curve\n",
    "        try:\n",
    "            popt, _ = curve_fit(gaussian, xs[idx], ys[idx], bounds=((-np.inf, -np.inf, 0), (np.inf, np.inf, np.inf)))\n",
    "            y_fit = gaussian(xs[idx], *popt)\n",
    "            popts.append(popt)\n",
    "\n",
    "            # Plot curve\n",
    "            plt.plot(xs[idx], y_fit, color=i_cols[a], alpha=0.75)\n",
    "        except:\n",
    "            popts.append(np.array([np.nan, np.nan, np.nan]))\n",
    "\n",
    "plt.xticks(ticks=[-1, 0, 1], labels=(\"-1.0\", \"0.0\", \"1.0\"))\n",
    "plt.xlabel('(L-R)/(L+R)')\n",
    "plt.ylabel(\"Sensitivity\")\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    plt.plot([], [], color=i_cols[a], alpha=0.75, label=i_labels[a])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.repeat([0,1,2,3], repeats=10)\n",
    "for l in [0, 1,2,3]:\n",
    "    print(np.round(np.nanmean(np.array(popts)[labels==l], axis=0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, popt in enumerate(popts):\n",
    "    if labels[a] != 0:\n",
    "        plt.scatter(labels[a], popt[2], color=i_cols[labels[a]], alpha=0.75)\n",
    "\n",
    "plt.xlabel('Architectures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_noise_scale = 0.05 \n",
    "n_steps = 6 \n",
    "\n",
    "maze = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze.generate(number=1000, noise_scale=0, gaps=2)\n",
    "\n",
    "fitness = np.zeros((len(agents), 8)) * np.nan\n",
    "\n",
    "for a in tqdm(range((len(agents)))): # for each network\n",
    "    wm_idx = [0] + list(np.where(agents[a].wm_flags)[0] + 1)\n",
    "    for b, wm in enumerate([np.inf] + list(np.arange(2, len(list(agents[a].parameters()))))): # for each weight matrix\n",
    "        agnt = copy.deepcopy(agents[a])\n",
    "        for c, param in enumerate(agnt.parameters()):\n",
    "            if c == wm: \n",
    "                param.data = torch.zeros(*param.shape)\n",
    "\n",
    "        fitness[a, wm_idx.pop(0)] = multimodal_mazes.eval_fitness(genome=None, config=None, channels=[1,1], sensor_noise_scale=sensor_noise_scale, drop_connect_p=0.0, maze=maze, n_steps=n_steps, agnt=agnt)\n",
    "\n",
    "fitness_norm = fitness - fitness[:,0][:,None]\n",
    "\n",
    "# np.save(\"./fitness\", fitness)\n",
    "# np.save(\"./fitness_norm\", fitness_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = np.load(\"./fitness.npy\")\n",
    "fitness_norm = np.load(\"./fitness_norm.npy\")\n",
    "\n",
    "interest = [1, 128, 74, 36]\n",
    "i_cols = ['xkcd:dusty blue', 'xkcd:purple', 'xkcd:dark seafoam', 'xkcd:yellowish']\n",
    "i_labels = ['Feedforward (L)', 'Fully recurrent', 'Most accurate', 'Most robust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.tile(np.arange(0,8), reps=fitness.shape[0]), y=fitness.reshape(-1), color='k', marker='.', alpha=0.5)\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    plt.scatter(x=np.tile(np.arange(0,8), reps=10), y=fitness[np.array(idxs) == i].reshape(-1), color=i_cols[a], marker='.', alpha=0.5)\n",
    "\n",
    "plt.xticks(ticks=np.arange(8), labels=(\"N\", \"L0\", \"L1\", \"L2\", \"S0\", \"S1\", \"B0\", \"B1\"))\n",
    "plt.xlabel('Ablation')\n",
    "plt.ylabel(\"Fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x=range(8),y=np.nanmean(fitness_norm, axis=0), yerr=np.nanstd(fitness_norm, axis=0), color='k', ls='None', marker='o')\n",
    "plt.xticks(ticks=np.arange(8), labels=(\"N\", \"L0\", \"L1\", \"L2\", \"S0\", \"S1\", \"B0\", \"B1\"));\n",
    "plt.xlabel('Ablation')\n",
    "plt.ylabel(\"Change in fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = np.linspace(start=-0.1, stop=0.1, num=4)\n",
    "for a, i in enumerate(interest):\n",
    "    plt.errorbar(\n",
    "        x=range(8) + np.repeat(offsets[a], repeats=8),\n",
    "        y=np.nanmean(fitness_norm[np.array(idxs) == i], axis=0), \n",
    "        yerr=np.nanstd(fitness_norm[np.array(idxs) == i], axis=0), \n",
    "        color=i_cols[a], ls='None', marker='o')\n",
    "\n",
    "plt.xticks(ticks=np.arange(8), labels=(\"N\", \"L0\", \"L1\", \"L2\", \"S0\", \"S1\", \"B0\", \"B1\"));\n",
    "plt.xlabel('Ablation')\n",
    "plt.ylabel(\"Change in fitness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As estimated MI \n",
    "\n",
    "# Calculating sensitivity\n",
    "sensor_noise_scale = 0.05\n",
    "n_steps = 6 \n",
    "\n",
    "maze = multimodal_mazes.TrackMaze(size=11, n_channels=2)\n",
    "maze.generate(number=1000, noise_scale=0, gaps=2)\n",
    "\n",
    "mi_norms = [[] for _ in interest]\n",
    "for a, i in enumerate(tqdm(interest)): # for each architecture\n",
    "    for _, v in enumerate(np.where(np.array(idxs) == i)[0]): # for each network\n",
    "        agnt = copy.deepcopy(agents[v])\n",
    "        all_states = []        \n",
    "\n",
    "        # Collect states\n",
    "        _, all_states = multimodal_mazes.eval_fitness(\n",
    "            genome=None, config=None, channels=agnt.channels, \n",
    "            sensor_noise_scale=sensor_noise_scale, drop_connect_p=0.0, \n",
    "            maze=maze, n_steps=n_steps, agnt=agnt, record_states=True)\n",
    "\n",
    "        # Estimate memory\n",
    "        mis = multimodal_mazes.estimate_dqn_memory(all_states=all_states, agnt=agnt, n_steps=n_steps)\n",
    "\n",
    "        mi_norms[a].append(mis)\n",
    "\n",
    "for a, i in enumerate(interest):\n",
    "    mi_norms[a] = np.array(mi_norms[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "for a, i in enumerate(interest):    \n",
    "    x = range(mi_norms[a].shape[1])\n",
    "    y = np.nanmean(mi_norms[a], axis=0)\n",
    "    sem = np.nanstd(mi_norms[a], axis=0) / np.sqrt(mi_norms[a].shape[0])\n",
    "    plt.plot(x, y, color=i_cols[a], label=i_labels[a])\n",
    "    plt.fill_between(x, y-sem, y+sem, color=i_cols[a], alpha=0.25, edgecolor=None)\n",
    "\n",
    "plt.ylim([-0.05,1.50])\n",
    "plt.legend()\n",
    "plt.xlabel('Temporal lag')\n",
    "plt.ylabel(\"Estimated MI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "for a, i in enumerate(interest):    \n",
    "    plt.scatter(np.ones(10) * a, np.sum(mi_norms[a], axis=1), color=i_cols[a])\n",
    "\n",
    "plt.xlabel('Temporal lag')\n",
    "plt.ylabel(\"Estimated MI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass \n",
    "\n",
    "L_input = [0.1,0.1]\n",
    "R_inputs = [[0.1, 0.0], [0.0, 0.1]]\n",
    "\n",
    "for a, i in enumerate(interest): # for each architecture \n",
    "    L_outputs = []\n",
    "    for i_num, v in enumerate(np.where(np.array(idxs) == i)[0]): # for each network\n",
    "        agnt = copy.deepcopy(agents[v])\n",
    "\n",
    "        for b in range(2):\n",
    "            l_outputs = [] \n",
    "            \n",
    "            # Reset agent\n",
    "            agnt.prev_input *= 0.0\n",
    "            agnt.hidden *= 0.0\n",
    "            agnt.prev_output *= 0.0\n",
    "            agnt.outputs *= 0.0\n",
    "            agnt.channel_inputs *= 0.0    \n",
    "\n",
    "            for t in range(6):\n",
    "\n",
    "                if t == 0:\n",
    "                    agnt.channel_inputs[0] = np.copy(L_input)\n",
    "                    agnt.channel_inputs[1] = np.copy(R_inputs[b])\n",
    "                else: \n",
    "                    agnt.channel_inputs *= 0.0\n",
    "\n",
    "                agnt.policy()\n",
    "                l_outputs.append(np.copy(agnt.outputs[0]))\n",
    "            L_outputs.append(l_outputs)\n",
    "\n",
    "    x = range(np.array(L_outputs).shape[1])\n",
    "    y = np.nanmean(np.array(L_outputs),axis=0)\n",
    "    sem = np.nanstd(np.array(L_outputs),axis=0) / np.sqrt(i_num + 1)\n",
    "    plt.plot(x, y, color=i_cols[a], label=i_labels[a])\n",
    "    plt.fill_between(x, y-sem, y+sem, color=i_cols[a], alpha=0.25, edgecolor=None)\n",
    "\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.legend()\n",
    "plt.xlabel('Time since input')\n",
    "plt.ylabel(\"p(Left)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, i in enumerate(interest): # for each architecture \n",
    "    L_outputs = []\n",
    "    for i_num, v in enumerate(np.where(np.array(idxs) == i)[0]): # for each network\n",
    "        agnt = copy.deepcopy(agents[v])\n",
    "\n",
    "        for _ in range(100):\n",
    "            l_outputs = [] \n",
    "            \n",
    "            # Reset agent\n",
    "            agnt.prev_input *= 0.0\n",
    "            agnt.hidden *= 0.0\n",
    "            agnt.prev_output *= 0.0\n",
    "            agnt.outputs *= 0.0\n",
    "            agnt.channel_inputs *= 0.0    \n",
    "\n",
    "            for t in range(6):\n",
    "                agnt.channel_inputs = np.random.normal(\n",
    "                    loc=0.0, scale=0.05, size=agnt.channel_inputs.shape\n",
    "                )\n",
    "                agnt.channel_inputs = np.clip(agnt.channel_inputs, a_min=0.0, a_max=1.0)\n",
    "                agnt.policy()\n",
    "                l_outputs.append(np.std(np.array(agnt.outputs)))\n",
    "            L_outputs.append(l_outputs)\n",
    "\n",
    "    x = range(np.array(L_outputs).shape[1])\n",
    "    y = np.nanmean(np.array(L_outputs),axis=0)\n",
    "    sem = np.nanstd(np.array(L_outputs),axis=0) / np.sqrt(i_num + 1)\n",
    "    plt.plot(x, y, color=i_cols[a], label=i_labels[a])\n",
    "    plt.fill_between(x, y-sem, y+sem, color=i_cols[a], alpha=0.25, edgecolor=None)\n",
    "\n",
    "plt.ylim([-0.05,0.45])\n",
    "plt.legend()\n",
    "plt.xlabel('Time with noise input')\n",
    "plt.ylabel(\"Std(p(outputs))\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
