{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multimodal_mazes\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters, Hyperparameters and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = {\n",
    "#     0: {'name': 'Up', 'delta': (-1, 0)},\n",
    "#     1: {'name': 'Down', 'delta': (1, 0)},\n",
    "#     2: {'name': 'Right', 'delta': (0, 1)},\n",
    "#     3: {'name': 'Left', 'delta': (0, -1)},\n",
    "#     4: {'name': 'Up-Right', 'delta': (-1, 1)},\n",
    "#     5: {'name': 'Up-Left', 'delta': (-1, -1)},\n",
    "#     6: {'name': 'Down-Right', 'delta': (1, 1)},\n",
    "#     7: {'name': 'Down-Left', 'delta': (1, -1)},\n",
    "# }\n",
    "\n",
    "# flags = {\n",
    "#     'lateral_input': False, \n",
    "#     'lateral_hidden': False, \n",
    "#     'lateral_output': False,\n",
    "#     'skip_input_output': False, \n",
    "#     'skip_output_input': False, \n",
    "#     'backward_output_hidden': False,\n",
    "#     'backward_hidden_input': False\n",
    "# }\n",
    "\n",
    "# scenario, multisensory, pc, pm, pe, noise, case, motion = static_hyperparamters()\n",
    "# agent = multimodal_mazes.DQNLearnerAgent(input_dim=input_dim, output_dim=output_dim, hidden_dim=hidden_dim, flags=flags, lr=lr, pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, gamma=gamma, epsilon=epsilon)\n",
    "# training_evaluator = multimodal_mazes.RLLinearPreyEvaluator(agent=agent, sensor_noise_scale=noise, pk=pk, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "# training_evaluator.train_RL(training_trials=2000)\n",
    "\n",
    "# input_dim = n_features\n",
    "# hidden_dim = len(actions)\n",
    "# output_dim = len(actions)\n",
    "# lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = 40\n",
    "n_trials = 100\n",
    "n_features = 12\n",
    "cost_per_step = -50\n",
    "cost_per_collision = -500\n",
    "epsilon = 0.5\n",
    "gamma = 0.9\n",
    "\n",
    "def environment_hyperparameters():\n",
    "    width = 21\n",
    "    height = 20\n",
    "    pk = 40\n",
    "    pk_hw = 20\n",
    "    return width, height, pk, pk_hw\n",
    "\n",
    "# def agent_hyperparameters():\n",
    "\n",
    "def static_hyperparamters():\n",
    "    noise = 0\n",
    "    n_prey = 1\n",
    "    n_steps = 50\n",
    "    scenario =  \"Static\"\n",
    "    motion = None\n",
    "    case = None\n",
    "    multisensory = \"Unisensory\"\n",
    "    speed = 0\n",
    "    pe = 1\n",
    "    pc = 0.0\n",
    "    return noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc\n",
    "\n",
    "def constant_hyperparameters():\n",
    "    noise = 0\n",
    "    n_prey = 1\n",
    "    n_steps = 50\n",
    "    scenario =  \"Constant\"\n",
    "    motion = \"Linear\"\n",
    "    case = None\n",
    "    multisensory = \"Unisensory\" \n",
    "    speed = 1\n",
    "    pe = 1\n",
    "    pc = 0.0\n",
    "    return noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, pk, pk_hw = environment_hyperparameters()\n",
    "noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc = static_hyperparamters()\n",
    "\n",
    "agent = multimodal_mazes.DQNLearnerAgent(input_dim=input_dim, output_dim=output_dim, hidden_dim=hidden_dim, flags=flags, lr=lr, pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, gamma=gamma, epsilon=epsilon)\n",
    "training_evaluator = multimodal_mazes.LinearPreyEvaluatorContinuous(width, height, pk_hw, agent, sensor_noise, n_prey, n_steps, visible_steps, scenario, motion, case, multisensory, speed, pe, pc)\n",
    "training_evaluator.train_RL(training_trials=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluator.training_plots(training_lengths=True, first_5_last_5=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Movement Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario, motion, multisensory, pc, pm, pe, noise, case, motion = constant_hyperparameters()\n",
    "agent = multimodal_mazes.QLearnerAgent(pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "training_evaluator = multimodal_mazes.LinearPreyEvaluator(width=width, height=height, agent=agent, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "training_evaluator.train_RL(training_trials = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluator.training_plots(percentage_captured=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluator.training_plots(first_5_last_5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluator.training_plots(animate=[True, 4894])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success vs Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Storage and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario, motion, multisensory, pc, pm, pe, noise, case, motion = constant_hyperparameters()\n",
    "n_agents = 4\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "pms = np.arange(0, 1.1, 0.1)\n",
    "case_colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "capture_results = np.zeros((n_agents, len(cases), len(pms)))\n",
    "approach_results = np.zeros((n_agents, len(cases), len(pms)))           \n",
    "trials = {n: {case: {pm: {} for pm in range(len(pms))} for case in range(len(cases))} for n in range(n_agents)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_agents):\n",
    "    agent = multimodal_mazes.QLearnerAgent(pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    evaluator = multimodal_mazes.LinearPreyEvaluator(width=width, height=height, agent=agent, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "    evaluator.train_RL(training_trials = 6000)\n",
    "\n",
    "    if n == n_agents - 1:\n",
    "        # evaluator.training_plots(percentage_captured=True)\n",
    "        evaluator.training_plots(first_5_last_5=True)\n",
    "\n",
    "    for case in range(len(cases)):\n",
    "        for a, pm in tqdm(enumerate(pms)):\n",
    "            test_trial_data, captured, approached = evaluator.evaluate(n_trials=n_trials, case=cases[case], pm=pm)\n",
    "            trials[n][case][a] = test_trial_data\n",
    "            capture_results[n, case, a] = captured\n",
    "            approach_results[n, case, a] = approached\n",
    "            # evaluator.agent.produce_plots(training_lengths=False, first_5_last_5=False, percentage_captured=False, animate=[True, 0], trials=test_trial_data, trial_lengths=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Processing and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_processed = np.zeros((2, len(cases), len(pms)))\n",
    "capture_results_mod = capture_results.copy()\n",
    "# capture_results_mod = np.delete(capture_results.copy(), , 0)\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        capture_processed[0, case, pm] = np.mean(capture_results_mod[:, case, pm])\n",
    "        capture_processed[1, case, pm] = np.std(capture_results_mod[:, case, pm])\n",
    "\n",
    "\n",
    "print('Capture Results:')\n",
    "print(capture_results)\n",
    "print('Processed Capture Results:')\n",
    "print(capture_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Capture Success vs Speed\")\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    axs[case].set_title(f\"Case {case + 1}\")\n",
    "    for n in range(n_agents):\n",
    "        axs[case].plot(pms, capture_results[n, case, :], color = case_colors[case], alpha = 0.2)\n",
    "    \n",
    "    axs[case].plot(pms, capture_processed[0, case, :], color=case_colors[case])\n",
    "    axs[case].errorbar(pms, capture_processed[0, case, :], yerr=capture_processed[1, case, :], color=case_colors[case])\n",
    "    axs[3].plot(pms, capture_processed[0, case, :], color=case_colors[case])\n",
    "    axs[3].errorbar(pms, capture_processed[0, case, :], yerr=capture_processed[1, case, :], color=case_colors[case])\n",
    "    \n",
    "axs[0].set(xlabel='Speed', ylabel='Capture Success')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_processed = np.zeros((2, len(cases), len(pms)))\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        approach_processed[0, case, pm] = np.mean(approach_results[:, case, pm])\n",
    "        approach_processed[1, case, pm] = np.std(approach_results[:, case, pm])\n",
    "\n",
    "print('Approach Results:')\n",
    "print(approach_results)\n",
    "print('Processed Approach Results:')\n",
    "print(approach_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Approach Success vs Speed\")\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    axs[case].set_title(f\"Case {case + 1}\")\n",
    "    for n in range(n_agents-1):\n",
    "        axs[case].plot(pms, approach_results[n, case, :], color = case_colors[case], alpha = 0.2)\n",
    "    \n",
    "    axs[case].plot(pms, approach_processed[0, case, :], color=case_colors[case])\n",
    "    axs[case].errorbar(pms, approach_processed[0, case, :], yerr=approach_processed[1, case, :], color=case_colors[case])\n",
    "    axs[3].plot(pms, approach_processed[0, case, :], color=case_colors[case])\n",
    "    axs[3].errorbar(pms, approach_processed[0, case, :], yerr=approach_processed[1, case, :], color=case_colors[case])\n",
    "    \n",
    "axs[0].set(xlabel='Speed', ylabel='Approach Success')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0: [plt.get_cmap('Blues')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          1: [plt.get_cmap('Oranges')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          2: [plt.get_cmap('Reds')(i) for i in np.arange(0, 1.1, 0.1)]}\n",
    "\n",
    "coords = {case: {'y': {pm: [] for pm in range(len(pms))}, 'x': {pm: [] for pm in range(len(pms))}} for case in range(len(cases))}\n",
    "mean_coords = {case: {'mean_x': {pm: [] for pm in range(len(pms))}, 'unique_y': {pm: [] for pm in range(len(pms))}} for case in range(len(cases))}\n",
    "    \n",
    "for case in range(len(cases)):\n",
    "    for agent in range(n_agents):          \n",
    "        for a in range(len(pms)):\n",
    "            x_coords, y_coords = [], []\n",
    "            \n",
    "            for trial in trials[agent][case][a]:\n",
    "                path = trials[agent][case][a][trial]['path']\n",
    "                for location in path:\n",
    "                    y = height + pk - location[0]\n",
    "                    x = width + pk - location[1] if path[0][1] < path[-1][1] else location[1]\n",
    "                    y_coords.append(y)\n",
    "                    x_coords.append(x)\n",
    "                    \n",
    "            coords[case]['y'][a] = y_coords\n",
    "            coords[case]['x'][a] = x_coords\n",
    "\n",
    "            x_values = np.array(x_coords)\n",
    "            y_values = np.array(y_coords)\n",
    "            unique_ys = np.unique(y_values)\n",
    "\n",
    "            mean_xs = np.array([x_values[y_values == y].mean() for y in unique_ys])\n",
    "            mean_coords[case]['mean_x'][a] = mean_xs\n",
    "            mean_coords[case]['unique_y'][a] = unique_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[0]['x'][a], coords[0]['y'][a], color=colors[0][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[0]['mean_x'][a], mean_coords[0]['unique_y'][a], label=np.round(pms[a], 1), color=colors[0][a])\n",
    "    \n",
    "plt.title('Case 1')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[1]['x'][a], coords[1]['y'][a], color=colors[1][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[1]['mean_x'][a], mean_coords[1]['unique_y'][a], label=np.round(pms[a], 1), color=colors[1][a])\n",
    "    \n",
    "plt.title('Case 2')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[2]['x'][a], coords[2]['y'][a], color=colors[2][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[2]['mean_x'][a], mean_coords[2]['unique_y'][a], label=np.round(pms[a], 1), color=colors[2][a])\n",
    "    \n",
    "    \n",
    "plt.title('Case 3')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum Learning Success vs Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Storage and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario, motion, multisensory, pc, pm, pe, noise, case, motion = constant_hyperparameters()\n",
    "n_agents = 4\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "pms = np.arange(0, 1.1, 0.1)\n",
    "case_colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "capture_results = np.zeros((n_agents, len(cases), len(pms)))\n",
    "approach_results = np.zeros((n_agents, len(cases), len(pms)))           \n",
    "trials = {n: {case: {pm: {} for pm in range(len(pms))} for case in range(len(cases))} for n in range(n_agents)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_agents):\n",
    "    agent = multimodal_mazes.QLearnerAgent(pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    evaluator = multimodal_mazes.LinearPreyEvaluator(width=width, height=height, agent=agent, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "    evaluator.train_RL(training_trials = 10000, curriculum=True)\n",
    "\n",
    "    if n == n_agents - 1:\n",
    "        # evaluator.training_plots(percentage_captured=True)\n",
    "        evaluator.training_plots(first_5_last_5=True)\n",
    "\n",
    "    for case in range(len(cases)):\n",
    "        for a, pm in tqdm(enumerate(pms)):\n",
    "            test_trial_data, captured, approached = evaluator.evaluate(n_trials=n_trials, case=cases[case], pm=pm)\n",
    "            trials[n][case][a] = test_trial_data\n",
    "            capture_results[n, case, a] = captured\n",
    "            approach_results[n, case, a] = approached\n",
    "            # evaluator.agent.produce_plots(training_lengths=False, first_5_last_5=False, percentage_captured=False, animate=[True, 0], trials=test_trial_data, trial_lengths=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Processing and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_processed = np.zeros((2, len(cases), len(pms)))\n",
    "capture_results_mod  = capture_results.copy()\n",
    "# capture_results_mod  = np.delete(capture_results.copy(), , )\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        capture_processed[0, case, pm] = np.mean(capture_results_mod[:, case, pm])\n",
    "        capture_processed[1, case, pm] = np.std(capture_results_mod[:, case, pm])\n",
    "\n",
    "print('Capture Results:')\n",
    "print(capture_results)\n",
    "print('Processed Capture Results:')\n",
    "print(capture_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Capture Success vs Speed\")\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    axs[case].set_title(f\"Case {case + 1}\")\n",
    "    for n in range(n_agents):\n",
    "        axs[case].plot(pms, capture_results[n, case, :], color = case_colors[case], alpha = 0.2)\n",
    "    \n",
    "    axs[case].plot(pms, capture_processed[0, case, :], color=case_colors[case])\n",
    "    axs[case].errorbar(pms, capture_processed[0, case, :], yerr=capture_processed[1, case, :], color=case_colors[case])\n",
    "    axs[3].plot(pms, capture_processed[0, case, :], color=case_colors[case])\n",
    "    axs[3].errorbar(pms, capture_processed[0, case, :], yerr=capture_processed[1, case, :], color=case_colors[case])\n",
    "    \n",
    "axs[0].set(xlabel='Speed', ylabel='Capture Success')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_processed = np.zeros((2, len(cases), len(pms)))\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        approach_processed[0, case, pm] = np.mean(approach_results[:, case, pm])\n",
    "        approach_processed[1, case, pm] = np.std(approach_results[:, case, pm])\n",
    "\n",
    "print('Approach Results:')\n",
    "print(approach_results)\n",
    "print('Processed Approach Results:')\n",
    "print(approach_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Approach Success vs Speed\")\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    axs[case].set_title(f\"Case {case + 1}\")\n",
    "    for n in range(n_agents):\n",
    "        axs[case].plot(pms, approach_results[n, case, :], color = case_colors[case], alpha = 0.2)\n",
    "    \n",
    "    axs[case].plot(pms, approach_processed[0, case, :], color=case_colors[case])\n",
    "    axs[case].errorbar(pms, approach_processed[0, case, :], yerr=approach_processed[1, case, :], color=case_colors[case])\n",
    "    axs[3].plot(pms, approach_processed[0, case, :], color=case_colors[case])\n",
    "    axs[3].errorbar(pms, approach_processed[0, case, :], yerr=approach_processed[1, case, :], color=case_colors[case])\n",
    "    \n",
    "axs[0].set(xlabel='Speed', ylabel='Approach Success')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0: [plt.get_cmap('Blues')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          1: [plt.get_cmap('Oranges')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          2: [plt.get_cmap('Reds')(i) for i in np.arange(0, 1.1, 0.1)]}\n",
    "\n",
    "coords = {case: {'y': {pm: [] for pm in range(len(pms))}, 'x': {pm: [] for pm in range(len(pms))}} for case in range(len(cases))}\n",
    "mean_coords = {case: {'mean_x': {pm: [] for pm in range(len(pms))}, 'unique_y': {pm: [] for pm in range(len(pms))}} for case in range(len(cases))}\n",
    "    \n",
    "for case in range(len(cases)):\n",
    "    for agent in range(n_agents):          \n",
    "        for a in range(len(pms)):\n",
    "            x_coords, y_coords = [], []\n",
    "            reverse_x = trials[agent][case][a][0]['path'][0][1] < trials[agent][case][a][0]['path'][-1][1] \n",
    "            \n",
    "            for trial in trials[agent][case][a]:\n",
    "                path = trials[agent][case][a][trial]['path']\n",
    "                for location in path:\n",
    "                    y = height + pk - location[0]\n",
    "                    x = width + pk - location[1] if path[0][1] < path[-1][1] else location[1]\n",
    "                    y_coords.append(y)\n",
    "                    x_coords.append(x)\n",
    "                    \n",
    "            coords[case]['y'][a] = y_coords\n",
    "            coords[case]['x'][a] = x_coords\n",
    "\n",
    "            x_values = np.array(x_coords)\n",
    "            y_values = np.array(y_coords)\n",
    "            unique_ys = np.unique(y_values)\n",
    "\n",
    "            mean_xs = np.array([x_values[y_values == y].mean() for y in unique_ys])\n",
    "            mean_coords[case]['mean_x'][a] = mean_xs\n",
    "            mean_coords[case]['unique_y'][a] = unique_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[0]['x'][a], coords[0]['y'][a], color=colors[0][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[0]['mean_x'][a], mean_coords[0]['unique_y'][a], label=np.round(pms[a], 1), color=colors[0][a])\n",
    "    \n",
    "plt.title('Case 1')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[1]['x'][a], coords[1]['y'][a], color=colors[1][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[1]['mean_x'][a], mean_coords[1]['unique_y'][a], label=np.round(pms[a], 1), color=colors[1][a])\n",
    "    \n",
    "plt.title('Case 2')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(pms)):\n",
    "    # plt.plot(coords[2]['x'][a], coords[2]['y'][a], color=colors[2][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[2]['mean_x'][a], mean_coords[2]['unique_y'][a], label=np.round(pms[a], 1), color=colors[2][a])\n",
    "    \n",
    "    \n",
    "plt.title('Case 3')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disappearing Success vs Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Storage and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario, motion, multisensory, pc, pm, pe, noise, case, motion = constant_hyperparameters()\n",
    "n_agents = 4\n",
    "visible_steps = None\n",
    "times_to_disappear = [1, 5, 10, 20]\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "pms = np.arange(0, 0.8, 0.25)\n",
    "case_colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "capture_results = np.zeros((n_agents, len(cases), len(pms), len(times_to_disappear)))\n",
    "approach_results = np.zeros((n_agents, len(cases), len(pms), len(times_to_disappear)))           \n",
    "trials = {n: {case: {pm: {time: {} for time in range(len(times_to_disappear))} for pm in range(len(pms))} for case in range(len(cases))} for n in range(n_agents)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_agents):\n",
    "    agent = multimodal_mazes.QLearnerAgent(pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    evaluator = multimodal_mazes.LinearPreyEvaluator(width=width, height=height, agent=agent, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "    evaluator.train_RL(training_trials = 10000)\n",
    "\n",
    "    if n == n_agents - 1:\n",
    "        # evaluator.training_plots(percentage_captured=True)\n",
    "        evaluator.training_plots(first_5_last_5=True)\n",
    "\n",
    "    for case in range(len(cases)):\n",
    "        for a, pm in tqdm(enumerate(pms)):\n",
    "            for b in range(len(times_to_disappear)):\n",
    "                visible_steps = times_to_disappear[b]\n",
    "                test_trial_data, captured, approached = evaluator.evaluate(n_trials=n_trials, case=cases[case], pm=pm, visible_steps=visible_steps)\n",
    "                trials[n][case][a][b] = test_trial_data\n",
    "                capture_results[n, case, a, b] = captured\n",
    "                approach_results[n, case, a, b] = approached\n",
    "                # evaluator.agent.produce_plots(training_lengths=False, first_5_last_5=False, percentage_captured=False, animate=[True, 0], trials=test_trial_data, trial_lengths=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Processing and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_processed = np.zeros((2, len(cases), len(pms), len(times_to_disappear)))\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        for time in range(len(times_to_disappear)):\n",
    "            approach_processed[0, case, pm, time] = np.mean(approach_results[:, case, pm, time])\n",
    "            approach_processed[1, case, pm, time] = np.std(approach_results[:, case, pm, time])\n",
    "\n",
    "print('Approach Results:')\n",
    "print(approach_results)\n",
    "print('Processed Approach Results:')\n",
    "print(approach_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Approach Success vs Time to Disappear per Speed\")\n",
    "\n",
    "# agents, cases, times, speeds\n",
    "\n",
    "for pm in range(len(pms)):\n",
    "    for case in range(len(cases)):\n",
    "        axs[pm].set_title(f\"Speed {pms[pm]}\")\n",
    "        # for n in range(n_agents):\n",
    "        #     axs[pm].plot(range(4), approach_results[n, case, pm, :], color = case_colors[case], alpha = 0.2)\n",
    "        \n",
    "        axs[pm].plot(range(4), approach_processed[0, case, pm, :], color=case_colors[case])\n",
    "        axs[pm].errorbar(range(4), approach_processed[0, case, pm, :], yerr=approach_processed[1, case, pm, :], color=case_colors[case])\n",
    "        \n",
    "labels = [str(time) for time in times_to_disappear]\n",
    "axs[0].set(xlabel='Time to Disappear', ylabel='Approach Success')\n",
    "axs[0].set_xticks(range(4), labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_mean_results = np.zeros((len(cases), len(times_to_disappear)))\n",
    "case_mean_results = np.mean(approach_processed[0, :, :, :], axis=1)\n",
    "\n",
    "for a, case in enumerate(case_mean_results):\n",
    "    plt.plot(range(4), case, color=case_colors[a])\n",
    "\n",
    "plt.xlim(3, 0)\n",
    "plt.xticks(range(4), labels);\n",
    "plt.title('Percentage Approached vs Time to Disappear')\n",
    "plt.xlabel('Time to Disappear')\n",
    "plt.ylabel('Percentage Approached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curriculum Disappearing Success vs Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Storage and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario, motion, multisensory, pc, pm, pe, noise, case, motion = constant_hyperparameters()\n",
    "n_agents = 4\n",
    "visible_steps = None\n",
    "times_to_disappear = [1, 5, 10, 20]\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "pms = np.arange(0, 0.8, 0.25)\n",
    "case_colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "capture_results = np.zeros((n_agents, len(cases), len(pms), len(times_to_disappear)))\n",
    "approach_results = np.zeros((n_agents, len(cases), len(pms), len(times_to_disappear)))           \n",
    "trials = {n: {case: {pm: {time: {} for time in range(len(times_to_disappear))} for pm in range(len(pms))} for case in range(len(cases))} for n in range(n_agents)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_agents):\n",
    "    agent = multimodal_mazes.QLearnerAgent(pk_hw=(pk//2), location=agent_location, channels=[1,1], actions=actions, sensor_noise_scale=noise, n_steps=n_steps, n_features=n_features, cost_per_step=cost_per_step, cost_per_collision=cost_per_collision, alpha=alpha, gamma=gamma, epsilon=epsilon)\n",
    "    evaluator = multimodal_mazes.LinearPreyEvaluator(width=width, height=height, agent=agent, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe)\n",
    "    evaluator.train_RL(training_trials = 10000, curriculum=True)\n",
    "\n",
    "    if n == n_agents - 1:\n",
    "        # evaluator.training_plots(percentage_captured=True)\n",
    "        evaluator.training_plots(first_5_last_5=True)\n",
    "\n",
    "    for case in range(len(cases)):\n",
    "        for a, pm in tqdm(enumerate(pms)):\n",
    "            for b in range(len(times_to_disappear)):\n",
    "                visible_steps = times_to_disappear[b]\n",
    "                test_trial_data, captured, approached = evaluator.evaluate(n_trials=n_trials, case=cases[case], pm=pm, visible_steps=visible_steps)\n",
    "                trials[n][case][a][b] = test_trial_data\n",
    "                capture_results[n, case, a, b] = captured\n",
    "                approach_results[n, case, a, b] = approached\n",
    "                # evaluator.agent.produce_plots(training_lengths=False, first_5_last_5=False, percentage_captured=False, animate=[True, 0], trials=test_trial_data, trial_lengths=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Processing and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_processed = np.zeros((2, len(cases), len(pms), len(times_to_disappear)))\n",
    "\n",
    "for case in range(len(cases)):\n",
    "    for pm in range(len(pms)):\n",
    "        for time in range(len(times_to_disappear)):\n",
    "            approach_processed[0, case, pm, time] = np.mean(approach_results[:, case, pm, time])\n",
    "            approach_processed[1, case, pm, time] = np.std(approach_results[:, case, pm, time])\n",
    "\n",
    "print('Approach Results:')\n",
    "print(approach_results)\n",
    "print('Processed Approach Results:')\n",
    "print(approach_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} RL Approach Success vs Time to Disappear per Speed\")\n",
    "\n",
    "# agents, cases, times, speeds\n",
    "\n",
    "for pm in range(len(pms)):\n",
    "    for case in range(len(cases)):\n",
    "        axs[pm].set_title(f\"Speed {pms[pm]}\")\n",
    "        # for n in range(n_agents):\n",
    "        #     axs[pm].plot(range(4), approach_results[n, case, pm, :], color = case_colors[case], alpha = 0.2)\n",
    "        \n",
    "        axs[pm].plot(range(4), approach_processed[0, case, pm, :], color=case_colors[case])\n",
    "        axs[pm].errorbar(range(4), approach_processed[0, case, pm, :], yerr=approach_processed[1, case, pm, :], color=case_colors[case])\n",
    "        \n",
    "labels = [str(time) for time in times_to_disappear]\n",
    "axs[0].set(xlabel='Time to Disappear', ylabel='Approach Success')\n",
    "axs[0].set_xticks(range(4), labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_mean_results = np.zeros((len(cases), len(times_to_disappear)))\n",
    "case_mean_results = np.mean(approach_processed[0, :, :, :], axis=1)\n",
    "\n",
    "for a, case in enumerate(case_mean_results):\n",
    "    plt.plot(range(4), case, color=case_colors[a])\n",
    "\n",
    "plt.xlim(3, 0)\n",
    "plt.xticks(range(4), labels);\n",
    "plt.title('Percentage Approached vs Time to Disappear')\n",
    "plt.xlabel('Time to Disappear')\n",
    "plt.ylabel('Percentage Approached')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
