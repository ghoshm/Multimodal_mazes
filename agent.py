# Agent
import numpy as np
import neat


class agent:
    def __init__(self, location, channels, genome, config):
        """
        Creates a new agent.
        Arguments:
            location: initial position [x,y]
            channels: list of active (1) and inative (0) channels e.g. [0,1]
        """
        self.location = np.array(location)
        self.channels = np.array(channels)

        # self.net = neat.nn.FeedForwardNetwork.create(genome, config)

    def sense(self, env):
        """
        Creates channel data for agent.
        Arguments:
            env: a np array of size x size x channels + 1.
            Where [:,:,-1] stores the maze structure.
        Returns:
            channel_inputs: channel, vector with input values
        """

        channel_inputs = np.copy(
            env[self.location[0], self.location[1], : len(self.channels)]
        )
        channel_inputs *= self.channels

        return channel_inputs

    def act(self, env, channel_inputs):
        """
        Updates the agent's state by one action.
        Arguments:
            env: a np array of size x size x channels + 1.
            Where [:,:,-1] stores the maze structure.
            channel_inputs: channel, vector with input values generated by sense
        """
        # Forward pass
        # output = net.activate(channel_inputs)
        output = [0, 0]  # TEST

        # Add noise to output (to avoid argmax bias)
        output += np.random.rand(len(output))

        # Choose action
        action = np.argmax(output)
        print(action)

        # Act
        if action == 0:
            if (self.location[1] - 1) >= 0.0:
                self.location += np.array([0, -1])
        elif action == 1:
            if (self.location[1] + 1) < env.shape[0]:
                self.location += np.array([0, 1])
